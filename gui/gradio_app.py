"""
Gradio GUI for GauzAssist Chatbot
æ”¯æŒå¼‚æ­¥æ“ä½œçš„ GUI ç‰ˆæœ¬

ç‰¹æ€§ï¼š
- åŸç”Ÿå¼‚æ­¥æ”¯æŒ
- å¤šæ ‡ç­¾é¡µç•Œé¢ï¼ˆèŠå¤© + ä»ªè¡¨ç›˜ï¼‰
- ä¸ CLI å…±äº«æ ¸å¿ƒé€»è¾‘
"""
import gradio as gr
import asyncio
import sys
from pathlib import Path
from uuid import uuid4
from datetime import datetime
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.infrastructure.database.session import get_db
from src.core.agent.memory_driven_agent import MemoryDrivenAgent
from src.core.utils.performance_tracker import PerformanceTracker
import time


def format_active_progress() -> tuple[str, str]:
    """æ ¼å¼åŒ–å½“å‰æ´»è·ƒè¯·æ±‚çš„è¿›åº¦

    Returns:
        (chat_display, dashboard_display): èŠå¤©ç•Œé¢æ˜¾ç¤ºå’Œä»ªè¡¨ç›˜æ˜¾ç¤º
    """
    active_requests = PerformanceTracker.get_active_requests()

    if not active_requests:
        return "", "æš‚æ— æ´»è·ƒè¯·æ±‚"

    # åªæ˜¾ç¤ºæœ€æ–°çš„æ´»è·ƒè¯·æ±‚
    req = active_requests[-1]
    elapsed = time.time() - req.start_time

    # Dashboard è¯¦ç»†æ˜¾ç¤º
    dashboard_output = f"### ğŸ”„ è¯·æ±‚ #{req.request_id}\n\n"
    dashboard_output += f"**æŸ¥è¯¢**: {req.user_query}\n\n"
    dashboard_output += f"**å·²è€—æ—¶**: {elapsed:.1f}s\n\n"

    # ä¸»æµç¨‹è¿›åº¦
    total_sync = len(req.sync_steps)
    completed_sync = sum(1 for s in req.sync_steps if s.status == "completed")
    progress_pct = (completed_sync / total_sync * 100) if total_sync > 0 else 0

    dashboard_output += f"**ä¸»æµç¨‹**: {completed_sync}/{total_sync} æ­¥éª¤ ({progress_pct:.0f}%)\n\n"

    # æ˜¾ç¤ºæ‰€æœ‰æ­¥éª¤
    for step in req.sync_steps:
        if step.status == "completed":
            icon = "âœ…"
            duration = f"{step.duration:.2f}s"
        elif step.status == "in_progress":
            icon = "â³"
            step_elapsed = time.time() - step.start_time
            duration = f"{step_elapsed:.1f}s..."
        else:
            icon = "â¸ï¸"
            duration = "ç­‰å¾…ä¸­"

        dashboard_output += f"- {icon} {step.name}: {duration}\n"

    # å¼‚æ­¥æ­¥éª¤
    if req.async_steps:
        dashboard_output += f"\n**åå°ä»»åŠ¡**:\n\n"
        for step in req.async_steps:
            if step.status == "completed":
                icon = "âœ…"
                duration = f"{step.duration:.2f}s"
            elif step.status == "in_progress":
                icon = "ğŸ”„"
                step_elapsed = time.time() - step.start_time
                duration = f"{step_elapsed:.1f}s..."
            else:
                icon = "â¸ï¸"
                duration = "ç­‰å¾…ä¸­"

            dashboard_output += f"- {icon} {step.name}: {duration}\n"

    # èŠå¤©ç•Œé¢ç®€åŒ–æ˜¾ç¤º
    chat_output = f"â±ï¸ å¤„ç†ä¸­... {elapsed:.0f}s ({progress_pct:.0f}%)"

    return chat_output, dashboard_output


def format_performance_data() -> str:
    """æ ¼å¼åŒ–æ€§èƒ½è¿½è¸ªæ•°æ®ä¸º Markdown"""
    requests = PerformanceTracker.get_recent_requests(limit=10)

    if not requests:
        return "### ğŸ“Š æ€§èƒ½è¿½è¸ª\n\næš‚æ— æ•°æ®"

    output = "### ğŸ“Š æœ€è¿‘è¯·æ±‚æ€§èƒ½è¿½è¸ª\n\n"

    for req in reversed(requests):  # æœ€æ–°çš„åœ¨å‰
        status_icon = "âœ…" if req.status == "completed" else "âŒ"
        output += f"#### {status_icon} è¯·æ±‚ #{req.request_id}\n"
        output += f"- **æŸ¥è¯¢**: {req.user_query[:50]}...\n"
        output += f"- **æ—¶é—´**: {req.timestamp}\n"
        output += f"- **æ€»è€—æ—¶**: {req.total_duration:.2f}s\n\n"

        # åŒæ­¥æ­¥éª¤
        output += "**ä¸»æµç¨‹**:\n"
        for step in req.sync_steps:
            icon = "âœ…" if step.status == "completed" else "â³" if step.status == "in_progress" else "âŒ"
            duration = f"{step.duration:.2f}s" if step.duration else "..."
            output += f"- {icon} {step.name}: {duration}\n"

        # å¼‚æ­¥æ­¥éª¤
        if req.async_steps:
            output += "\n**åå°ä»»åŠ¡**:\n"
            for step in req.async_steps:
                icon = "âœ…" if step.status == "completed" else "â³" if step.status == "in_progress" else "âŒ"
                duration = f"{step.duration:.2f}s" if step.duration else "..."
                output += f"- {icon} {step.name}: {duration}\n"

        output += "\n---\n\n"

    return output


def format_context_content(request_id: str = None) -> str:
    """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡å†…å®¹ä¸º Markdown

    Args:
        request_id: è¯·æ±‚ IDï¼Œå¦‚æœä¸º None åˆ™æ˜¾ç¤ºæœ€æ–°è¯·æ±‚
    """
    requests = PerformanceTracker.get_recent_requests(limit=10)

    if not requests:
        return "### ğŸ“ ä¸Šä¸‹æ–‡å†…å®¹\n\næš‚æ— æ•°æ®"

    # æ‰¾åˆ°æŒ‡å®šçš„è¯·æ±‚ï¼Œæˆ–ä½¿ç”¨æœ€æ–°çš„
    target_req = None
    if request_id:
        for req in requests:
            if req.request_id == request_id:
                target_req = req
                break
    else:
        target_req = requests[-1]  # æœ€æ–°çš„è¯·æ±‚

    if not target_req or not target_req.context_content:
        return "### ğŸ“ ä¸Šä¸‹æ–‡å†…å®¹\n\næš‚æ— ä¸Šä¸‹æ–‡æ•°æ®"

    ctx = target_req.context_content
    output = f"### ğŸ“ è¯·æ±‚ #{target_req.request_id} çš„ä¸Šä¸‹æ–‡å†…å®¹\n\n"
    output += f"**æŸ¥è¯¢**: {target_req.user_query}\n\n"
    output += "---\n\n"

    # 1. æŠ€èƒ½ Prompt
    if ctx.get("skill_prompt"):
        output += "#### ğŸ¯ æŠ€èƒ½ Prompt\n\n"
        output += f"```\n{ctx['skill_prompt'][:500]}...\n```\n\n" if len(ctx['skill_prompt']) > 500 else f"```\n{ctx['skill_prompt']}\n```\n\n"
    else:
        output += "#### ğŸ¯ æŠ€èƒ½ Prompt\n\næ— \n\n"

    # 2. çº¿ä¸Šè®°å¿†
    output += "#### ğŸŒ çº¿ä¸Šè®°å¿†\n\n"
    online_memories = ctx.get("online_memories", [])
    if online_memories:
        output += f"å…± {len(online_memories)} æ¡è®°å¿†:\n\n"
        for i, mem in enumerate(online_memories[:5], 1):  # åªæ˜¾ç¤ºå‰5æ¡
            content = mem.get("content", mem.get("text", ""))
            output += f"{i}. {content[:100]}...\n" if len(content) > 100 else f"{i}. {content}\n"
        if len(online_memories) > 5:
            output += f"\n... è¿˜æœ‰ {len(online_memories) - 5} æ¡è®°å¿†\n"
    else:
        output += "æ— \n"
    output += "\n"

    # 4. å¯¹è¯å†å²
    output += "#### ğŸ’¬ å¯¹è¯å†å²\n\n"
    conv_history = ctx.get("conversation_history", [])
    if conv_history:
        output += f"å…± {len(conv_history)} æ¡æ¶ˆæ¯:\n\n"
        for i, msg in enumerate(conv_history[-3:], 1):  # åªæ˜¾ç¤ºæœ€è¿‘3æ¡
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            output += f"{i}. **{role}**: {content}\n"
    else:
        output += "æ— \n"
    output += "\n"

    # 5. ç»Ÿè®¡ä¿¡æ¯
    output += "#### ğŸ“Š ç»Ÿè®¡ä¿¡æ¯\n\n"
    output += f"- System Prompt é•¿åº¦: {ctx.get('system_prompt_length', 0)} å­—ç¬¦\n"
    output += f"- æ€»æ¶ˆæ¯æ•°: {ctx.get('total_messages', 0)}\n"

    return output


class ChatbotGUI:
    """Gradio èŠå¤©æœºå™¨äºº GUI"""

    def __init__(self):
        self.session_id = str(uuid4())
        self.message_count = 0

    async def process_message(
        self,
        message: str,
        history: List[Tuple[str, str]],
        progress=gr.Progress()
    ) -> Tuple[List[Tuple[str, str]], str]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯

        Args:
            message: ç”¨æˆ·è¾“å…¥
            history: å¯¹è¯å†å²
            progress: Gradio è¿›åº¦æ¡

        Returns:
            (æ›´æ–°åçš„å†å², ç©ºå­—ç¬¦ä¸²)
        """
        if not message.strip():
            return history, ""

        try:
            async for db in get_db():
                agent = MemoryDrivenAgent(db, use_reasoner=False)

                # åˆå§‹åŒ–è¿›åº¦
                progress(0, desc="ğŸ”„ å¼€å§‹å¤„ç†...")

                response = await agent.process_message(
                    user_message=message,
                    session_id=self.session_id,
                    progress_callback=progress
                )

                await db.commit()

                if response["success"]:
                    response_text = response["text"]
                else:
                    response_text = f"âŒ é”™è¯¯: {response.get('error', 'æœªçŸ¥é”™è¯¯')}"

                # æ›´æ–°å†å²
                history.append((message, response_text))
                self.message_count += 1

                return history, ""

        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"âŒ é”™è¯¯è¯¦æƒ…:\n{error_detail}")
            error_msg = f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"
            history.append((message, error_msg))
            return history, ""

    def clear_chat(self) -> Tuple[List, str]:
        """æ¸…é™¤å¯¹è¯"""
        self.session_id = str(uuid4())
        self.message_count = 0
        return [], f"ä¼šè¯å·²é‡ç½®\næ–°ä¼šè¯ ID: {self.session_id[:8]}..."

    def get_session_info(self) -> str:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        return f"""
### ğŸ“Š ä¼šè¯ä¿¡æ¯

- **ä¼šè¯ ID**: `{self.session_id[:8]}...`
- **æ¶ˆæ¯æ•°**: {self.message_count}
- **åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""


def create_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    chatbot_gui = ChatbotGUI()

    with gr.Blocks(
        title="GauzAssist Chat",
        theme=gr.themes.Soft()
    ) as demo:
        gr.Markdown("# ğŸ’¬ GauzAssist Chat")
        gr.Markdown("åŸºäºè®°å¿†é©±åŠ¨çš„æ™ºèƒ½åŠ©æ‰‹ - Gradio ç‰ˆæœ¬")

        with gr.Tabs():
            # æ ‡ç­¾é¡µ 1: èŠå¤©ç•Œé¢
            with gr.Tab("ğŸ’¬ èŠå¤©"):
                with gr.Row():
                    with gr.Column(scale=3):
                        chatbot = gr.Chatbot(
                            label="å¯¹è¯",
                            height=400,
                            show_copy_button=True,
                            type="tuples"
                        )

                        # å®æ—¶è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
                        active_progress_display = gr.Markdown(
                            value="",
                            visible=True,
                            label="å¤„ç†è¿›åº¦"
                        )

                        with gr.Row():
                            msg = gr.Textbox(
                                label="è¾“å…¥æ¶ˆæ¯",
                                placeholder="è¾“å…¥æ¶ˆæ¯...",
                                lines=2,
                                scale=4
                            )
                            submit_btn = gr.Button("å‘é€", variant="primary", scale=1)

                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", variant="secondary")

                    with gr.Column(scale=1):
                        session_info = gr.Markdown(chatbot_gui.get_session_info())

                        gr.Markdown("### âš™ï¸ è®¾ç½®")
                        gr.Markdown("æ›´å¤šè®¾ç½®å³å°†æ¨å‡º...")

            # æ ‡ç­¾é¡µ 2: ä»ªè¡¨ç›˜
            with gr.Tab("ğŸ“Š ä»ªè¡¨ç›˜"):
                # æ´»è·ƒè¯·æ±‚åŒºåŸŸ
                gr.Markdown("## ğŸ”„ æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚")
                active_requests_display = gr.Markdown(
                    value=format_active_progress()[1],  # åªå– dashboard éƒ¨åˆ†
                    label="å®æ—¶è¿›åº¦"
                )

                gr.Markdown("---")

                # å†å²è¯·æ±‚åŒºåŸŸ
                gr.Markdown("## ğŸ“œ å†å²è¯·æ±‚")
                performance_display = gr.Markdown(
                    value=format_performance_data(),
                    label="æ€§èƒ½è¿½è¸ª"
                )

                with gr.Row():
                    refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ•°æ®", variant="primary")
                    clear_history_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å†å²", variant="secondary")

                gr.Markdown("---")

                # ä¸Šä¸‹æ–‡å†…å®¹åŒºåŸŸ
                gr.Markdown("## ğŸ“ ä¸Šä¸‹æ–‡å†…å®¹")
                context_display = gr.Markdown(
                    value=format_context_content(),
                    label="ä¸Šä¸‹æ–‡å†…å®¹"
                )

                refresh_context_btn = gr.Button("ğŸ”„ åˆ·æ–°ä¸Šä¸‹æ–‡", variant="primary")

                gr.Markdown("### ğŸ“ˆ åŠŸèƒ½è¯´æ˜")
                gr.Markdown("""
                - **ä¸»æµç¨‹**: åŒæ­¥æ‰§è¡Œçš„æ­¥éª¤ï¼ŒæŒ‰é¡ºåºå®Œæˆ
                - **åå°ä»»åŠ¡**: å¼‚æ­¥æ‰§è¡Œçš„æ­¥éª¤ï¼Œä¸é˜»å¡ä¸»æµç¨‹
                - æ¯ä¸ªè¯·æ±‚éƒ½ä¼šè®°å½•å„æ­¥éª¤çš„è€—æ—¶ï¼Œå¸®åŠ©å®šä½æ€§èƒ½ç“¶é¢ˆ
                """)

        # å®šæ—¶å™¨ï¼šæ¯ 2 ç§’åˆ·æ–°ä¸€æ¬¡è¿›åº¦
        timer = gr.Timer(value=2, active=True)
        timer.tick(
            fn=format_active_progress,
            outputs=[active_progress_display, active_requests_display]
        )

        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            fn=chatbot_gui.process_message,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )

        msg.submit(
            fn=chatbot_gui.process_message,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )

        clear_btn.click(
            fn=chatbot_gui.clear_chat,
            outputs=[chatbot, session_info]
        )

        # Dashboard äº‹ä»¶ç»‘å®š
        refresh_btn.click(
            fn=format_performance_data,
            outputs=performance_display
        )

        def clear_performance_history():
            PerformanceTracker.clear_history()
            return format_performance_data()

        clear_history_btn.click(
            fn=clear_performance_history,
            outputs=performance_display
        )

        refresh_context_btn.click(
            fn=format_context_content,
            outputs=context_display
        )

    return demo


if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
