#!/usr/bin/env python3
"""
å®éªŒ 04: è§†è§‰ + ä»£ç è”åˆåˆ†æ
=========================

ç›®æ ‡ï¼šæ¼”ç¤ºå¦‚ä½•ç»“åˆ AI è§†è§‰åˆ†æå’Œ DXF ä»£ç åˆ†ææ¥ç†è§£å»ºç­‘å›¾çº¸

å·¥ä½œæµç¨‹ï¼š
1. è§†è§‰åˆ†æ PDF - ç†è§£å›¾çº¸æ•´ä½“ç»“æ„å’Œè®¾è®¡æ„å›¾
2. ä»£ç åˆ†æ DXF - ç²¾ç¡®æå–å’Œæµ‹é‡æ„ä»¶
3. ç»“æœå¯¹æ¯”éªŒè¯ - æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§

è¾“å…¥ï¼š
- temp_workspace/input/ç”²ç±»ä»“åº“å»ºæ–½.pdf
- temp_workspace/input/ç”²ç±»ä»“åº“å»ºæ–½.dxf

è¾“å‡ºï¼š
- temp_workspace/analysis/visual_report.json - è§†è§‰åˆ†ææŠ¥å‘Š
- temp_workspace/analysis/code_analysis.json - ä»£ç åˆ†æç»“æœ
- temp_workspace/analysis/comparison_report.md - å¯¹æ¯”éªŒè¯æŠ¥å‘Š
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import ezdxf
from openai import OpenAI
from dotenv import load_dotenv
from pdf2image import convert_from_path
from PIL import Image
import io

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env")


class VisualCodeAnalyzer:
    """è§†è§‰ + ä»£ç è”åˆåˆ†æå™¨"""

    def __init__(self, workspace_dir: str = None):
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå·¥ä½œç›®å½•ï¼Œä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•
        if workspace_dir is None:
            script_dir = Path(__file__).parent
            self.workspace = script_dir
        else:
            self.workspace = Path(workspace_dir)

        self.input_dir = self.workspace / "input"
        self.output_dir = self.workspace / "output"
        self.analysis_dir = self.workspace / "analysis"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.analysis_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ– Kimi å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ OpenAI SDKï¼‰
        self.client = OpenAI(
            api_key=os.getenv("VISION_MODEL_API_KEY"),
            base_url=os.getenv("VISION_MODEL_BASE_URL")
        )
        self.model_name = os.getenv("VISION_MODEL_NAME", "moonshot-v1-vision")

    def _pdf_to_images(self, pdf_path: Path, max_pages: int = 3) -> List[str]:
        """
        å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡ï¼ˆbase64 ç¼–ç ï¼‰

        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            max_pages: æœ€å¤šè½¬æ¢çš„é¡µæ•°

        Returns:
            å›¾ç‰‡çš„ base64 ç¼–ç åˆ—è¡¨
        """
        print(f"ğŸ“„ æ­£åœ¨å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡ï¼ˆæœ€å¤š {max_pages} é¡µï¼‰...")

        try:
            # è½¬æ¢ PDF ä¸ºå›¾ç‰‡
            images = convert_from_path(pdf_path, dpi=150, first_page=1, last_page=max_pages)

            base64_images = []
            for i, image in enumerate(images):
                # å‹ç¼©å›¾ç‰‡ä»¥å‡å°å¤§å°
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=85)
                buffer.seek(0)

                import base64
                img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
                base64_images.append(img_base64)
                print(f"  âœ“ ç¬¬ {i+1} é¡µè½¬æ¢å®Œæˆ")

            return base64_images

        except Exception as e:
            print(f"âŒ PDF è½¬å›¾ç‰‡å¤±è´¥: {e}")
            return []

    def step1_visual_analysis(self, pdf_path: Path) -> Dict[str, Any]:
        """
        æ­¥éª¤ 1: è§†è§‰åˆ†æ PDF

        ä½¿ç”¨ Kimi K2.5 çš„è§†è§‰èƒ½åŠ›åˆ†æ PDFï¼Œç†è§£ï¼š
        - å›¾çº¸ç±»å‹å’Œç”¨é€”
        - ä¸»è¦æ„ä»¶å’Œå¸ƒå±€
        - å›¾å±‚å’Œæ ‡æ³¨ä¿¡æ¯
        - è®¾è®¡ç‰¹ç‚¹
        """
        print("\n" + "="*60)
        print("æ­¥éª¤ 1: è§†è§‰åˆ†æ PDF")
        print("="*60)

        print(f"ğŸ“„ æ­£åœ¨åˆ†æ: {pdf_path.name}")

        # å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡
        image_base64_list = self._pdf_to_images(pdf_path, max_pages=3)

        if not image_base64_list:
            return {"error": "PDF è½¬å›¾ç‰‡å¤±è´¥"}

        # è°ƒç”¨ Claude è¿›è¡Œè§†è§‰åˆ†æ
        prompt = """è¯·åˆ†æè¿™ä»½å»ºç­‘æ–½å·¥å›¾çº¸ï¼Œæä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. **å›¾çº¸åŸºæœ¬ä¿¡æ¯**
   - å›¾çº¸ç±»å‹ï¼ˆå¹³é¢å›¾/ç«‹é¢å›¾/å‰–é¢å›¾ç­‰ï¼‰
   - å»ºç­‘ç”¨é€”å’Œè§„æ¨¡
   - å›¾çº¸ç¼–å·å’Œæ¯”ä¾‹

2. **ä¸»è¦æ„ä»¶è¯†åˆ«**
   - å¢™ä½“ï¼ˆå¤–å¢™ã€å†…å¢™ã€å¢™åšï¼‰
   - æŸ±å­ï¼ˆä½ç½®ã€å°ºå¯¸ï¼‰
   - é—¨çª—ï¼ˆæ•°é‡ã€ç±»å‹ï¼‰
   - æ¥¼æ¢¯ï¼ˆä½ç½®ã€ç±»å‹ï¼‰
   - å…¶ä»–é‡è¦æ„ä»¶

3. **å›¾å±‚å’Œæ ‡æ³¨**
   - ä¸»è¦å›¾å±‚åŠå…¶é¢œè‰²
   - è½´çº¿ç¼–å·
   - å°ºå¯¸æ ‡æ³¨
   - æ–‡å­—è¯´æ˜

4. **è®¾è®¡ç‰¹ç‚¹**
   - ç©ºé—´å¸ƒå±€ç‰¹ç‚¹
   - ç»“æ„ç‰¹ç‚¹
   - éœ€è¦ç‰¹åˆ«æ³¨æ„çš„åœ°æ–¹

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼å›ç­”ï¼Œä¾¿äºåç»­ä»£ç åˆ†æä½¿ç”¨ã€‚"""

        try:
            # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼šå…ˆæ·»åŠ æ‰€æœ‰å›¾ç‰‡ï¼Œæœ€åæ·»åŠ æ–‡æœ¬æç¤º
            content = []
            for i, img_base64 in enumerate(image_base64_list):
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_base64}"
                    }
                })

            # æ·»åŠ æ–‡æœ¬æç¤º
            content.append({
                "type": "text",
                "text": prompt
            })

            print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ Kimi K2.5 åˆ†æ {len(image_base64_list)} é¡µå›¾çº¸...")

            # ä½¿ç”¨ Kimi çš„ OpenAI å…¼å®¹æ ¼å¼
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{
                    "role": "user",
                    "content": content
                }],
                temperature=1  # Kimi K2.5 è¦æ±‚ temperature å¿…é¡»ä¸º 1
            )

            visual_report = {
                "timestamp": datetime.now().isoformat(),
                "pdf_file": pdf_path.name,
                "analysis": response.choices[0].message.content,
                "model": self.model_name
            }

            # ä¿å­˜æŠ¥å‘Š
            report_path = self.analysis_dir / "visual_report.json"
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(visual_report, f, ensure_ascii=False, indent=2)

            print(f"âœ… è§†è§‰åˆ†æå®Œæˆ")
            print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            print("\n" + "-"*60)
            print("è§†è§‰åˆ†ææ‘˜è¦:")
            print("-"*60)
            print(response.choices[0].message.content[:500] + "...")

            return visual_report

        except Exception as e:
            print(f"âŒ è§†è§‰åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}

    def step2_code_analysis(self, dxf_path: Path) -> Dict[str, Any]:
        """
        æ­¥éª¤ 2: DXF ä»£ç åˆ†æ

        ä½¿ç”¨ ezdxf ç²¾ç¡®æå–å’Œæµ‹é‡ï¼š
        - å›¾å±‚ç»Ÿè®¡
        - å®ä½“ç±»å‹ç»Ÿè®¡
        - å¢™ä½“é•¿åº¦
        - é—¨çª—æ•°é‡
        - å…¶ä»–æ„ä»¶ä¿¡æ¯
        """
        print("\n" + "="*60)
        print("æ­¥éª¤ 2: DXF ä»£ç åˆ†æ")
        print("="*60)

        print(f"ğŸ“ æ­£åœ¨åˆ†æ: {dxf_path.name}")

        try:
            # è¯»å– DXF æ–‡ä»¶
            doc = ezdxf.readfile(dxf_path)
            msp = doc.modelspace()

            # 1. å›¾å±‚ç»Ÿè®¡
            layers = {}
            for entity in msp:
                layer = entity.dxf.layer
                if layer not in layers:
                    layers[layer] = {"count": 0, "types": {}}
                layers[layer]["count"] += 1

                entity_type = entity.dxftype()
                if entity_type not in layers[layer]["types"]:
                    layers[layer]["types"][entity_type] = 0
                layers[layer]["types"][entity_type] += 1

            print(f"\nğŸ“Š å›¾å±‚ç»Ÿè®¡: å…± {len(layers)} ä¸ªå›¾å±‚")
            for layer_name, info in sorted(layers.items(), key=lambda x: x[1]["count"], reverse=True)[:10]:
                print(f"  - {layer_name}: {info['count']} ä¸ªå®ä½“")

            # 2. å®ä½“ç±»å‹ç»Ÿè®¡
            entity_types = {}
            for entity in msp:
                entity_type = entity.dxftype()
                entity_types[entity_type] = entity_types.get(entity_type, 0) + 1

            print(f"\nğŸ“¦ å®ä½“ç±»å‹ç»Ÿè®¡: å…± {len(entity_types)} ç§ç±»å‹")
            for entity_type, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True)[:10]:
                print(f"  - {entity_type}: {count} ä¸ª")

            code_analysis = {
                "timestamp": datetime.now().isoformat(),
                "dxf_file": dxf_path.name,
                "layers": layers,
                "entity_types": entity_types,
                "total_entities": len(list(msp))
            }

            # ä¿å­˜åˆ†æç»“æœ
            analysis_path = self.analysis_dir / "code_analysis.json"
            with open(analysis_path, 'w', encoding='utf-8') as f:
                json.dump(code_analysis, f, ensure_ascii=False, indent=2)

            print(f"\nâœ… ä»£ç åˆ†æå®Œæˆ")
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜: {analysis_path}")

            return code_analysis

        except Exception as e:
            print(f"âŒ ä»£ç åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}

    def step3_comparison(self, visual_report: Dict, code_analysis: Dict) -> str:
        """
        æ­¥éª¤ 3: ç»“æœå¯¹æ¯”éªŒè¯

        å°†è§†è§‰åˆ†æå’Œä»£ç åˆ†æç»“æœè¿›è¡Œå¯¹æ¯”ï¼Œç”ŸæˆéªŒè¯æŠ¥å‘Š
        """
        print("\n" + "="*60)
        print("æ­¥éª¤ 3: ç»“æœå¯¹æ¯”éªŒè¯")
        print("="*60)

        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        report_lines = [
            "# è§†è§‰ + ä»£ç è”åˆåˆ†ææŠ¥å‘Š",
            "",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "## 1. è§†è§‰åˆ†ææ‘˜è¦",
            "",
            "### å›¾çº¸ç†è§£",
            ""
        ]

        if "analysis" in visual_report:
            report_lines.append(visual_report["analysis"])
        else:
            report_lines.append("è§†è§‰åˆ†æå¤±è´¥")

        report_lines.extend([
            "",
            "## 2. ä»£ç åˆ†æç»“æœ",
            "",
            f"- **æ€»å®ä½“æ•°**: {code_analysis.get('total_entities', 0)}",
            f"- **å›¾å±‚æ•°é‡**: {len(code_analysis.get('layers', {}))}",
            f"- **å®ä½“ç±»å‹**: {len(code_analysis.get('entity_types', {}))}",
            "",
            "### ä¸»è¦å›¾å±‚",
            ""
        ])

        # åˆ—å‡ºå‰ 10 ä¸ªå›¾å±‚
        layers = code_analysis.get('layers', {})
        for layer_name, info in sorted(layers.items(), key=lambda x: x[1]["count"], reverse=True)[:10]:
            report_lines.append(f"- **{layer_name}**: {info['count']} ä¸ªå®ä½“")

        report_lines.extend([
            "",
            "### å®ä½“ç±»å‹åˆ†å¸ƒ",
            ""
        ])

        # åˆ—å‡ºå‰ 10 ä¸ªå®ä½“ç±»å‹
        entity_types = code_analysis.get('entity_types', {})
        for entity_type, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True)[:10]:
            report_lines.append(f"- **{entity_type}**: {count} ä¸ª")

        report = "\n".join(report_lines)

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.analysis_dir / "comparison_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"âœ… å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ")
        print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        return report

    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„è§†è§‰+ä»£ç è”åˆåˆ†ææµç¨‹"""
        print("\n" + "="*60)
        print("ğŸš€ å¼€å§‹è§†è§‰ + ä»£ç è”åˆåˆ†æ")
        print("="*60)

        # æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶
        pdf_file = self.input_dir / "ç”²ç±»ä»“åº“å»ºæ–½.pdf"
        dxf_file = self.input_dir / "ç”²ç±»ä»“åº“å»ºæ–½.dxf"

        if not pdf_file.exists():
            print(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
            return

        if not dxf_file.exists():
            print(f"âŒ DXF æ–‡ä»¶ä¸å­˜åœ¨: {dxf_file}")
            return

        # æ­¥éª¤ 1: è§†è§‰åˆ†æ
        visual_report = self.step1_visual_analysis(pdf_file)

        # æ­¥éª¤ 2: ä»£ç åˆ†æ
        code_analysis = self.step2_code_analysis(dxf_file)

        # æ­¥éª¤ 3: ç»“æœå¯¹æ¯”
        comparison_report = self.step3_comparison(visual_report, code_analysis)

        print("\n" + "="*60)
        print("âœ… åˆ†æå®Œæˆï¼")
        print("="*60)
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {self.analysis_dir}")
        print(f"  - visual_report.json - è§†è§‰åˆ†ææŠ¥å‘Š")
        print(f"  - code_analysis.json - ä»£ç åˆ†æç»“æœ")
        print(f"  - comparison_report.md - å¯¹æ¯”éªŒè¯æŠ¥å‘Š")


def main():
    """ä¸»å‡½æ•°"""
    analyzer = VisualCodeAnalyzer()
    analyzer.run_full_analysis()


if __name__ == "__main__":
    main()
